{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Методы решения задачи одномерной минимизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "алгоритмическая сложность, преимущества каждого алгоритма и какой метод предпочтительнее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Метод Дитохондрии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          a         b         l        x1        x2      f_x1      f_x2\n",
      "0 -2.000000  1.000000  3.000000 -0.505000 -0.495000 -4.754975 -4.744975\n",
      "1 -2.000000 -0.495000  1.505000 -1.252500 -1.242500 -4.936244 -4.941194\n",
      "2 -1.252500 -0.495000  0.757500 -0.878750 -0.868750 -4.985298 -4.982773\n",
      "3 -1.252500 -0.868750  0.383750 -1.065625 -1.055625 -4.995693 -4.996906\n",
      "4 -1.065625 -0.868750  0.196875 -0.972187 -0.962187 -4.999226 -4.998570\n",
      "5 -1.065625 -0.962187  0.103437 -1.018906 -1.008906 -4.999643 -4.999921\n",
      "6 -1.018906 -0.962187  0.056719 -0.995547 -0.985547 -4.999980 -4.999791\n",
      "7 -1.018906 -0.985547  0.033359 -1.007227 -0.997227 -4.999948 -4.999992\n",
      "8 -1.007227 -0.985547  0.021680 -1.001387 -0.991387 -4.999998 -4.999926\n",
      "9 -1.007227 -0.991387  0.015840       NaN       NaN       NaN       NaN\n",
      "-0.9993066406249997\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from typing import Callable\n",
    "\n",
    "def ditohondria(\n",
    "    f: Callable[[float], float],\n",
    "    interval: tuple[float,float],\n",
    "    eps: float   \n",
    ") -> float:\n",
    "    table = pd.DataFrame(columns=['a','b','l','x1','x2','f_x1','f_x2'])\n",
    "\n",
    "    a, b = interval\n",
    "    while b - a > 2 * eps:\n",
    "        x1 = (a + b)/2 - eps/2\n",
    "        x2 = (a + b)/2 + eps/2\n",
    "\n",
    "        f_x1, f_x2 = f(x1), f(x2)\n",
    "\n",
    "        table.loc[len(table)] = [a, b, b-a, x1, x2, f_x1, f_x2]\n",
    "\n",
    "        a, b = (x1, b) if f_x1 > f_x2 else (a, x2)\n",
    "\n",
    "    table.loc[len(table)] = [a, b, b-a] + [None]*4\n",
    "    \n",
    "    return table, (a + b) / 2\n",
    "\n",
    "### пример ###\n",
    "f = lambda x: x**2 + 2*x - 4\n",
    "table, answer = ditohondria(f, (-2, 1), 0.01)\n",
    "\n",
    "print(table)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Метод Фибоначчи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          a         b         l        x1        x2      f_x1      f_x2\n",
      "0 -2.000000  1.000000  3.000000 -0.852941 -0.147059 -4.978374 -4.272491\n",
      "1 -2.000000 -0.147059  1.852941 -1.294118 -0.852941 -4.913495 -4.978374\n",
      "2 -1.294118 -0.147059  1.147059 -0.852941 -0.588235 -4.978374 -4.830450\n",
      "3 -1.294118 -0.588235  0.705882 -1.029412 -0.852941 -4.999135 -4.978374\n",
      "4 -1.294118 -0.852941  0.441176 -1.117647 -1.029412 -4.986159 -4.999135\n",
      "5 -1.117647 -0.852941  0.264706 -1.029412 -0.941176 -4.999135 -4.996540\n",
      "6 -1.117647 -0.852941  0.264706       NaN       NaN       NaN       NaN\n",
      "-0.9852941176470587\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from typing import Callable\n",
    "\n",
    "def fibonacci(\n",
    "    f: Callable[[float], float],\n",
    "    interval: tuple[float, float],\n",
    "    eps: float\n",
    ") -> float:\n",
    "    a, b = interval\n",
    "\n",
    "    table = pd.DataFrame(\n",
    "        columns=['a','b','l','x1','x2','f_x1','f_x2']\n",
    "        )\n",
    "    \n",
    "    F = [1, 1]\n",
    "    while F[-1] < (b - a) / eps:\n",
    "        F.append(F[-1] + F[-2])\n",
    "    \n",
    "    delta = (b - a) / F[-1]\n",
    "    \n",
    "    N = len(F) - 1\n",
    "    \n",
    "    x1 = a + F[N - 2] * delta\n",
    "    x2 = b - F[N - 2] * delta\n",
    "\n",
    "    f_x1, f_x2 = f(x1), f(x2)\n",
    "\n",
    "    table.loc[len(table)] = [a, b, b-a, x1, x2, f_x1, f_x2]\n",
    "\n",
    "    for k in range(1, N - 2):\n",
    "        if f_x1 < f_x2:\n",
    "            b = x2\n",
    "            x2, f_x2 = x1, f_x1\n",
    "            x1 = a + F[N - k - 2] * delta\n",
    "            f_x1 = f(x1)\n",
    "        else:\n",
    "            a = x1\n",
    "            x1, f_x1 = x2, f_x2\n",
    "            x2 = b - F[N - k - 2] * delta\n",
    "            f_x2 = f(x2)\n",
    "        table.loc[len(table)] = [a, b, b-a, x1, x2, f_x1, f_x2]\n",
    "    \n",
    "    table.loc[len(table)] = [a, b, b-a] + [None]*4\n",
    "\n",
    "    return table, (a + b) / 2\n",
    "\n",
    "f = lambda x: x**2 + 2*x - 4\n",
    "table, result = fibonacci(f, (-2, 1), 0.1)\n",
    "\n",
    "print(table)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Метод золотого сечения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          a         b         l        x1        x2      f_x1      f_x2\n",
      "0 -2.000000  1.000000  3.000000 -0.854102 -0.145898 -4.978714 -4.270510\n",
      "1 -2.000000 -0.145898  1.854102 -1.291796 -0.854102 -4.914855 -4.978714\n",
      "2 -1.291796 -0.145898  1.145898 -0.854102 -0.583592 -4.978714 -4.826604\n",
      "3 -1.291796 -0.583592  0.708204 -1.021286 -0.854102 -4.999547 -4.978714\n",
      "4 -1.291796 -0.854102  0.437694 -1.124612 -1.021286 -4.984472 -4.999547\n",
      "5 -1.124612 -0.854102  0.270510 -1.021286 -0.957428 -4.999547 -4.998188\n",
      "6 -1.124612 -0.957428  0.167184 -1.060753 -1.021286 -4.996309 -4.999547\n",
      "7 -1.124612 -0.957428  0.167184       NaN       NaN       NaN       NaN\n",
      "-1.0410196624968455\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from typing import Callable\n",
    "import pandas as pd\n",
    "\n",
    "def golden_ratio(\n",
    "    f: Callable[[float], float],\n",
    "    interval: tuple[float, float],\n",
    "    eps: float\n",
    ") -> float:\n",
    "\n",
    "    table = pd.DataFrame(\n",
    "        columns=['a','b','l','x1','x2','f_x1','f_x2']\n",
    "        )\n",
    "    \n",
    "    a, b = interval\n",
    "    \n",
    "    alfa = (3 - sqrt(5)) / 2\n",
    "\n",
    "    x1 = a + alfa * (b - a)\n",
    "    x2 = b - alfa * (b - a)\n",
    "\n",
    "    f_x1, f_x2 = f(x1), f(x2)\n",
    "    \n",
    "    table.loc[len(table)] = [a, b, b-a, x1, x2, f_x1, f_x2]\n",
    "\n",
    "    while b - a > 2 * eps:\n",
    "        if f_x1 > f_x2:\n",
    "            a = x1\n",
    "            x1, f_x1 = x2, f_x2\n",
    "            x2 = b - alfa * (b - a)\n",
    "            f_x2 = f(x2)\n",
    "        else:\n",
    "            b = x2\n",
    "            x2, f_x2 = x1, f_x1\n",
    "            x1 = a + alfa * (b - a)\n",
    "            f_x1 = f(x1)\n",
    "        table.loc[len(table)] = [a, b, b-a, x1, x2, f_x1, f_x2] \n",
    "    \n",
    "    table.loc[len(table)] = [a, b, b-a] + [None]*4\n",
    "\n",
    "    return table, (a + b) / 2\n",
    "\n",
    "f = lambda x: x**2 + 2*x - 4\n",
    "table, result = golden_ratio(f, (-2, 1), 0.1)\n",
    "\n",
    "print(table)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Метод деления пополам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        a       b       l       x  grad_f(x)\n",
      "0 -3.0000  6.0000  9.0000  1.5000     5.0000\n",
      "1 -3.0000  1.5000  4.5000 -0.7500     0.5000\n",
      "2 -3.0000 -0.7500  2.2500 -1.8750    -1.7500\n",
      "3 -1.8750 -0.7500  1.1250 -1.3125    -0.6250\n",
      "4 -1.3125 -0.7500  0.5625 -1.0312    -0.0625\n",
      "5 -1.0312 -0.7500  0.2812 -0.8906     0.2188\n",
      "6 -1.0312 -0.8906  0.1406     NaN        NaN\n",
      "-0.9609375\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from math import log, ceil\n",
    "from autograd import grad\n",
    "from typing import Callable\n",
    "\n",
    "def bisection_method(\n",
    "    f: Callable[[float], float],\n",
    "    interval: tuple[float, float],\n",
    "    eps: float\n",
    "):\n",
    "    table = pd.DataFrame(\n",
    "        columns=['a','b','l','x','grad_f(x)']\n",
    "        )\n",
    "    \n",
    "    a, b = interval\n",
    "    \n",
    "    N = ceil( log(2 * eps / (b - a)) / (log(1) - log(2)) )\n",
    "\n",
    "    x = 0\n",
    "    for k in range(0, N):\n",
    "        x = (a + b) / 2\n",
    "\n",
    "        grad_f_x = grad(f)(x)\n",
    "\n",
    "        table.loc[len(table)] = [a, b, b-a, x, grad_f_x] \n",
    "\n",
    "        if grad_f_x == 0:\n",
    "            return x\n",
    "        elif grad_f_x > 0:\n",
    "            b = x\n",
    "        else:\n",
    "            a = x\n",
    "\n",
    "    table.loc[len(table)] = [a, b, b-a] + [None] * 2\n",
    "\n",
    "    return table, (a + b) / 2\n",
    "\n",
    "\n",
    "f = lambda x: x**2 + 2*x\n",
    "table, result = bisection_method(f,(-3, 6), 0.1)\n",
    "\n",
    "print(table.round(4))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Метод Ньютона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    x0  grad_f(x0)  grad2_f(x0)        x1\n",
      "0  0.4    1.152000     3.840000  0.100000\n",
      "1  0.4    0.108000     2.040000  0.047059\n",
      "2  0.4    0.025324     1.049689  0.022934\n",
      "3  0.4    0.006167     0.531475  0.011331\n",
      "4  0.4    0.001523     0.267315  0.005633\n",
      "5  0.4    0.000379     0.134042  0.002808\n",
      "6  0.4    0.000094     0.067116  0.001402\n",
      "7  0.4    0.000024     0.033582  0.000701\n",
      "0.0007006044051493947\n"
     ]
    }
   ],
   "source": [
    "from autograd import grad\n",
    "from typing import Callable\n",
    "import pandas as pd\n",
    "\n",
    "def newton_method(\n",
    "    f: Callable[[float], float],\n",
    "    x: float,\n",
    "    eps: float\n",
    ") -> float:\n",
    "    table = pd.DataFrame(\n",
    "        columns=['x0', 'grad_f(x0)','grad2_f(x0)', 'x1']\n",
    "        )\n",
    "    \n",
    "    x1, x0 = x, 0\n",
    "    \n",
    "    while abs(x1 - x0) > eps or grad(f)(x1) > eps:\n",
    "        x0 = x1\n",
    "        \n",
    "        grad_f_x0, grad2_f_x0 = grad(f)(x0), grad(grad(f))(x0)\n",
    "        \n",
    "        x1 = x0 - grad_f_x0 / grad2_f_x0\n",
    "        \n",
    "        table.loc[len(table)] = [x, grad_f_x0, grad2_f_x0, x1]\n",
    "        \n",
    "    return table, x1\n",
    "    \n",
    "f = lambda x: 4*x**3 - 3*x**4\n",
    "table, result = newton_method(f, 0.4, 0.001)\n",
    "\n",
    "print(table)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Методы решения задачи многомерной минимизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Метод циклического покооринатного спуска (not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def cyclic_coordinate_descent(\n",
    "    f: Callable,\n",
    "    eps: float\n",
    "):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Метод Хука и Дживса (not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "norm = np.linalg.norm\n",
    "\n",
    "### Дано\n",
    "x = np.array([0.2, 0.1])\n",
    "\n",
    "d = np.array([0.15, 0.1])\n",
    "\n",
    "alfa = 2\n",
    "\n",
    "eps = 0.1\n",
    "\n",
    "f = lambda x: x[0]**2 + x[0]*x[1] + 2*x[1]**2 + x[0] - x[1]\n",
    "\n",
    "### Решение\n",
    "x0 = x.copy()\n",
    "\n",
    "N = len(x)\n",
    "\n",
    "d = d * np.eye(N)\n",
    "\n",
    "for i in range(N):\n",
    "    if f( x + d[i] ) < f(x):\n",
    "        x += d[i]\n",
    "    elif f( x - d[i] ) < f(x):\n",
    "        x -= d[i]\n",
    "f(x + (x - x0)) < f(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Метод Роземброка (not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Градиентный метод с дроблением шага"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  x0    f_x     grad_f_x (s)  alfa                 x1    f_x  \\\n",
      "0             [0, 0]  0.000          [-1, 1]  1.00            [-1, 1]  0.000   \n",
      "1             [0, 0]  0.000          [-1, 1]  0.50        [-0.5, 0.5] -0.500   \n",
      "2        [-0.5, 0.5] -0.500     [-0.5, -0.5]  1.00        [-1.0, 0.0]  0.000   \n",
      "3        [-0.5, 0.5] -0.500     [-0.5, -0.5]  0.50      [-0.75, 0.25] -0.500   \n",
      "4        [-0.5, 0.5] -0.500     [-0.5, -0.5]  0.25    [-0.625, 0.375] -0.562   \n",
      "5    [-0.625, 0.375] -0.562  [-0.125, 0.125]  1.00       [-0.75, 0.5] -0.562   \n",
      "6    [-0.625, 0.375] -0.562  [-0.125, 0.125]  0.50  [-0.6875, 0.4375] -0.570   \n",
      "7  [-0.6875, 0.4375] -0.570             None   NaN               None    NaN   \n",
      "\n",
      "   -d*alfa*norm(s) f(x1)-f(x) > -d*alfa*norm(s)  \n",
      "0           -0.200                         True  \n",
      "1           -0.100                        False  \n",
      "2           -0.050                         True  \n",
      "3           -0.025                         True  \n",
      "4           -0.013                        False  \n",
      "5           -0.003                         True  \n",
      "6           -0.002                        False  \n",
      "7              NaN                         None  \n",
      "[-0.6875  0.4375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Azerty\\AppData\\Local\\Temp\\ipykernel_2884\\522973379.py:63: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  table.loc[len(table)] = [x1, f(*x1)] + [None]*6\n"
     ]
    }
   ],
   "source": [
    "import sympy as sym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "norm = np.linalg.norm\n",
    "\n",
    "def gradient_splitting_step(\n",
    "    f: sym.Add,\n",
    "    x0: np.ndarray,\n",
    "    alfa: float,\n",
    "    d: float\n",
    "):\n",
    "    x1 = x0\n",
    "\n",
    "    alfa_start_value = alfa\n",
    "\n",
    "    table = pd.DataFrame(\n",
    "        columns=['x0','f_x','grad_f_x (s)','alfa','x1','f_x','-d*alfa*norm(s)','f(x1)-f(x) > -d*alfa*norm(s)'])\n",
    "\n",
    "    # переменные\n",
    "    variables = tuple(f.free_symbols)\n",
    "\n",
    "    # сортировка переменных по числу\n",
    "    variables = sorted(variables, key=\n",
    "                       lambda var: int(sym.srepr(var)[-3]))\n",
    "\n",
    "    # градиент функции по всем переменным\n",
    "    gradients_f = [\n",
    "        sym.diff(f, variable) for variable in variables]\n",
    "\n",
    "    # превращение из символьного представления в функцию\n",
    "    gradients_f = [\n",
    "        sym.lambdify(variables, gradient_f) \n",
    "                   for gradient_f in gradients_f]\n",
    "    \n",
    "    # преващение из символьного представления в функцию\n",
    "    f = sym.lambdify(variables, f)\n",
    "    \n",
    "    for k in range(1000):\n",
    "        alfa = alfa_start_value\n",
    "        \n",
    "        # градиент в точке (или s)\n",
    "        grad_f_x = - np.array([f(*x1) for f in gradients_f])\n",
    "\n",
    "        x = x1 + alfa * grad_f_x\n",
    "\n",
    "        while f(*x) - f(*x1) >= - d * alfa * norm(grad_f_x)**2:\n",
    "            table.loc[len(table)] = [\n",
    "                x0, f(*x0), grad_f_x, alfa, x, f(*x), -d*alfa*norm(grad_f_x)**2, True\n",
    "            ]\n",
    "            \n",
    "            alfa /= 2\n",
    "            \n",
    "            x = x1 + alfa * grad_f_x\n",
    "\n",
    "        table.loc[len(table)] = [\n",
    "                x0, f(*x0), grad_f_x, alfa, x, f(*x), -d*alfa*norm(grad_f_x)**2, False\n",
    "            ]\n",
    "\n",
    "        x1 = x\n",
    "        \n",
    "        if norm(x - x0) <= eps:\n",
    "            table.loc[len(table)] = [x1, f(*x1)] + [None]*6\n",
    "            return table, x1\n",
    "        \n",
    "        x0 = x1\n",
    "\n",
    "x = np.array([0, 0])\n",
    "alfa = 1\n",
    "d = 0.1\n",
    "eps = 0.1\n",
    "\n",
    "x1, x2 = sym.symbols('x1 x2')\n",
    "f = x1**2 + x1*x2 + 2*x2**2 + x1 - x2\n",
    "\n",
    "table, result = gradient_splitting_step(f, x, alfa, d)\n",
    "\n",
    "print(table.round(3))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10) Метод наискорейшего спуска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.6875,  0.4375])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sympy as sym\n",
    "import numpy as np\n",
    "\n",
    "norm = np.linalg.norm\n",
    "\n",
    "def get_alfa_from_x_and_gradient(f):\n",
    "    # переменные\n",
    "    variables = tuple(f.free_symbols)\n",
    "\n",
    "    # сортировка переменных по числу: x1,x2,...,xn\n",
    "    variables = sorted(variables, key=\n",
    "                       lambda var: int(sym.srepr(var)[-3]))\n",
    "\n",
    "    N = len(variables)\n",
    "\n",
    "    # градиент функции по всем переменным\n",
    "    gradients_f = [\n",
    "        sym.diff(f, variable) for variable in variables]\n",
    "\n",
    "    a = sym.symbols('a')\n",
    "\n",
    "    # составляем переменные s_i для каждого x_i\n",
    "    s_variables = list(sym.symbols(' '.join([\n",
    "        f's{sym.srepr(variable)[-3]}' for variable in variables\n",
    "    ])))\n",
    "\n",
    "    # [(x_i, a*s_i + x_i)] - лист кортежей с заменой\n",
    "    replacement = [(variables[i], variables[i] + a * s_variables[i]) \n",
    "                    for i in range(N)]\n",
    "\n",
    "    # градиент функции по всем переменным\n",
    "    gradients_f = [\n",
    "        sym.diff(f, variable) for variable in variables]\n",
    "\n",
    "    # заменяем переменные в градиенте\n",
    "    gradients_f = [\n",
    "        f.subs(replacement) for f in gradients_f\n",
    "    ]\n",
    "\n",
    "    # домножаем градиент по каждой переменной на s_i\n",
    "    expr = sum([gradients_f[i] * s_variables[i] \n",
    "                for i in range(N)])\n",
    "    \n",
    "    # выражаем a\n",
    "    solution = sym.solve(expr, a)[0]\n",
    "\n",
    "    return sym.lambdify(variables + s_variables, solution)\n",
    "\n",
    "def get_gradient(f, x0):\n",
    "    # переменные\n",
    "    variables = tuple(f.free_symbols)\n",
    "\n",
    "    # сортировка переменных по числу\n",
    "    variables = sorted(variables, key=\n",
    "                       lambda var: int(sym.srepr(var)[-3]))\n",
    "\n",
    "    # градиент функции по всем переменным\n",
    "    gradients_f = [\n",
    "        sym.diff(f, variable) for variable in variables]\n",
    "\n",
    "    # превращение из символьного представления в функцию\n",
    "    lambd_gradients_f = [\n",
    "        sym.lambdify(variables, gradient_f) \n",
    "                    for gradient_f in gradients_f]\n",
    "    \n",
    "    grad_f_x = np.array([f(*x0) for f in lambd_gradients_f])\n",
    "\n",
    "    return np.where(np.abs(grad_f_x) > 0.0001, grad_f_x, 0)\n",
    "\n",
    "def steepest_descent(\n",
    "    f: sym.Add,\n",
    "    x0: np.ndarray,\n",
    "    eps: float\n",
    "):\n",
    "    x1 = x0\n",
    "\n",
    "    alfa = get_alfa_from_x_and_gradient(f)\n",
    "\n",
    "    for k in range(1000):\n",
    "        grad_f_x = get_gradient(f, x1)\n",
    "        \n",
    "        alfa_ = alfa(*x1, *-grad_f_x)\n",
    "\n",
    "        x1 = x0 + alfa_ * -grad_f_x\n",
    "\n",
    "        if norm(x1 - x0) < eps:\n",
    "            return x1\n",
    "        x0 = x1\n",
    "\n",
    "### Дано\n",
    "x1, x2 = sym.symbols('x1 x2')\n",
    "f = x1**2 + x1*x2 + 2*x2**2 + x1 - x2\n",
    "\n",
    "x0 = np.array([0, 0])\n",
    "eps = 0.1\n",
    "\n",
    "steepest_descent(f, x0, eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11) Метод Ньютона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<lambdifygenerated-10534>:2: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return (1/2)*(-2*s1*x1 - s1*x2 - s1 - s2*x1 - 4*s2*x2 + s2)/(s1**2 + s1*s2 + 2*s2**2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.71428571,  0.42857143])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sympy as sym\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "\n",
    "def Newton(\n",
    "    f: sym.Add,\n",
    "    x0: np.ndarray,\n",
    "    eps: float\n",
    "):\n",
    "    x1 = x0\n",
    "\n",
    "    variables = tuple(f.free_symbols)\n",
    "\n",
    "    # сортировка переменных по числу\n",
    "    variables = sorted(variables, key=\n",
    "                        lambda var: int(sym.srepr(var)[-3]))\n",
    "\n",
    "    N = len(variables)\n",
    "\n",
    "    pairs = np.array(\n",
    "        [var for var in product(variables,repeat=2)])\n",
    "\n",
    "    gesse = np.array(\n",
    "        [f.diff(*pair) for pair in pairs], dtype='float64'\n",
    "    ).reshape((N,N))\n",
    "\n",
    "    gesse_inverse = np.linalg.inv(gesse)\n",
    "\n",
    "    alfa = get_alfa_from_x_and_gradient(f)\n",
    "\n",
    "    for k in range(1000):\n",
    "        grad_f_x = get_gradient(f, x1)\n",
    "\n",
    "        s = -(gesse_inverse @ grad_f_x)\n",
    "\n",
    "        alfa_ = alfa(*x1, *s)\n",
    "\n",
    "        alfa_ = alfa_ if abs(alfa_) > 0.001 else 0\n",
    "\n",
    "        x1 = x0 + alfa_ * s\n",
    "\n",
    "        if norm(x1 - x0) < eps:\n",
    "            return x1\n",
    "        \n",
    "        x0 = x1\n",
    "\n",
    "### Дано\n",
    "x1, x2 = sym.symbols('x1 x2')\n",
    "f = x1**2 + x1*x2 + 2*x2**2 + x1 - x2\n",
    "\n",
    "x0 = np.array([0, 0])\n",
    "eps = 0.1\n",
    "\n",
    "Newton(f,x0, eps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оставшиеся\n",
    "1. Метод циклического покооринатного спуска\n",
    "2. Метод Хука и Дживса\n",
    "3. Метод Роземброка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Условная оптимизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оставшиеся\n",
    "1. методы возможных направлений\n",
    "2. метод зойтендейка\n",
    "3. метод проекции градиента розена\n",
    "4. метод приведенного градиента вулфа\n",
    "5. методы штрафных и барьерных функций"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
